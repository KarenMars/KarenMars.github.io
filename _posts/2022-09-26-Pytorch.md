## Reading pytorch tutorials 



<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [Reading pytorch tutorials](#reading-pytorch-tutorials)
  - [How to create a dataset for pytorch ?](#how-to-create-a-dataset-for-pytorch)
    - [Customize dataset](#customize-dataset)
  - [Iterate through the DataLoader](#iterate-through-the-dataloader)

<!-- /code_chunk_output -->

### How to create a dataset for pytorch ? 


>  PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples. 

- Dataset: torch.utils.data.Dataset
- Dataloader: torch.utils.data.Dataloader 

#### Customize dataset
```Python
class CustomDataset(Dataset):
    """
    customDataset stores samples and their targets,
    return the length of the dataset, 
    return an instance of sample and target of the dataset
    """
    def __init__(self, datapath):
        self.datapath = datapath
        
        self.data = []
        self.label = []

        # iterate entries in datapath
        with open(datapath, 'r') as f:
            line = f.readline()
            
            # add entries to self.data and self.label
        
    def __len__(self):
        """
        return the number of entries in the datapath
        """
        return len(self.data)
    
    def __getitem__(self,index):
        """
        return a sample from the dataset at the given index
        """

        return self.data[index], self.label[index]
```


### Iterate through the DataLoader

> The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval. 

- [shuffle](https://blog.csdn.net/qq_44901346/article/details/115770988)
    - `shuffle = True`: shuffle batch data in each epoch
    - setting seed: ensure each training process with the same random. 









